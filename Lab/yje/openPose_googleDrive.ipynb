{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "openPose_googleDrive.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBpAkifiX13r"
      },
      "source": [
        "# Goal : Pose Detection with OpenPose\n",
        "\n",
        "This notebook uses an open source project [CMU-Perceptual-Computing-Lab/openpose](https://github.com/CMU-Perceptual-Computing-Lab/openpose.git) to detect/track multi person poses on a given video.\n",
        "\n",
        "For other deep-learning Colab notebooks, visit [tugstugi/dl-colab-notebooks](https://github.com/tugstugi/dl-colab-notebooks)\n",
        "\n",
        " - Build : google drive update"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whRAmu12nNb5"
      },
      "source": [
        "# google drive "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB9tWW2puj8-"
      },
      "source": [
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E79J2yPUzpyn"
      },
      "source": [
        "!rm -rf \"/content/openpose\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWYDYJJNnRky"
      },
      "source": [
        "# cmake & git clone & Openpose build copy \n",
        " - google drive : My Drive/tmp/openpose  \n",
        " - origin : !cd openpose && rm -rf build || true && mkdir build && cd build && cmake .. && make -j`nproc` -> folder copy to google drive\n",
        " - download from google drive and change auth openpose.bin ( chmod )\n",
        "\n",
        " - No performance improvement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySE28F2EztdF"
      },
      "source": [
        "from os.path import exists, join, basename, splitext\n",
        "\n",
        "git_repo_url = 'https://github.com/CMU-Perceptual-Computing-Lab/openpose.git'\n",
        "project_name = splitext(basename(git_repo_url))[0]\n",
        "if not exists(project_name):\n",
        "  # see: https://github.com/CMU-Perceptual-Computing-Lab/openpose/issues/949\n",
        "  # install new CMake becaue of CUDA10\n",
        "  !wget -q https://cmake.org/files/v3.13/cmake-3.13.0-Linux-x86_64.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2JY0y4szxi9"
      },
      "source": [
        "!tar xfz cmake-3.13.0-Linux-x86_64.tar.gz --strip-components=1 -C /usr/local\n",
        "# clone openpose\n",
        "!git clone -q --depth 1 $git_repo_url\n",
        "!sed -i 's/execute_process(COMMAND git checkout master WORKING_DIRECTORY ${CMAKE_SOURCE_DIR}\\/3rdparty\\/caffe)/execute_process(COMMAND git checkout f019d0dfe86f49d1140961f8c7dec22130c83154 WORKING_DIRECTORY ${CMAKE_SOURCE_DIR}\\/3rdparty\\/caffe)/g' openpose/CMakeLists.txt\n",
        "# install system dependencies\n",
        "!apt-get -qq install -y libatlas-base-dev libprotobuf-dev libleveldb-dev libsnappy-dev libhdf5-serial-dev protobuf-compiler libgflags-dev libgoogle-glog-dev liblmdb-dev opencl-headers ocl-icd-opencl-dev libviennacl-dev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMimD2dLu1Ab"
      },
      "source": [
        "!cp -r \"/content/drive/My Drive/tmp/openpose/\" /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXH6rMYqvA8k"
      },
      "source": [
        "!ls -ltr /content/openpose/build/examples/openpose\n",
        "!chmod u+x /content/openpose/build/examples/openpose/openpose.bin\n",
        "!ls -ltr /content/openpose/build/examples/openpose"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDNWdgNNoCZt"
      },
      "source": [
        "# Input data copy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6Pu5WLnvX2p"
      },
      "source": [
        "!rm -rf \"./yoga_video/\"\n",
        "os.mkdir(\"./yoga_video/\")\n",
        "\n",
        "!wget -q https://archive.org/download/YogaVidCollected/Yoga_Vid_Collected.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiV2xZuDvava"
      },
      "source": [
        "!unzip Yoga_Vid_Collected.zip -d yoga_video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6uqNj9uoIvv"
      },
      "source": [
        "# Openpose model/input/output path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "webRPSzvKSe2"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "model_path = '/content/openpose'  \n",
        "input_path = '/content/yoga_video'\n",
        "output_path = '/content/output'\n",
        "output_file_path = \"\".join([output_path, '/file'])\n",
        "output_json_path = \"\".join([output_path, '/json'])\n",
        "\n",
        "os.system(f\"rm -rf '{output_path}'\")\n",
        "os.mkdir(output_path)\n",
        "os.mkdir(output_file_path)\n",
        "os.mkdir(output_json_path)\n",
        "\n",
        "input_file_type = \"mp4\"\n",
        "input_cut_time = 10\n",
        "\n",
        "%cd $model_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tguLACxyoWtN"
      },
      "source": [
        "# Pose Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ET9rU81Mr6V"
      },
      "source": [
        "def detect_keypoint_file(file_name):\n",
        "\n",
        "  origin_file_path = \"\".join([output_path, '/', file_name.split('/')[-1]])\n",
        "  origin_file_name = file_name.split('/')[-1].split('.')[0]\n",
        "\n",
        "  temp_file_name = \"\".join([output_path, '/', 'openpose.avi'])\n",
        "  output_file_name = \"\".join([output_file_path, '/', origin_file_name, '.', input_file_type])\n",
        "  output_json_name = \"\".join([output_json_path, '/', origin_file_name])\n",
        "    \n",
        "  os.system(f\"ffmpeg -y -loglevel info -i '{file_name}' -t {input_cut_time} '{origin_file_path}'\")\n",
        "  os.system(f\"./build/examples/openpose/openpose.bin --keypoint_scale 3 --frame_step 3 --video '{origin_file_path}' --write_json '{output_json_name}/' --display 0 --write_video '{temp_file_name}'\")\n",
        "  os.system(f\"ffmpeg -y -loglevel info -i '{temp_file_name}' '{output_file_name}'\")\n",
        "  os.system(f\"rm -rf '{origin_file_path}'\")\n",
        "  os.system(f\"rm -rf '{temp_file_name}'\")\n",
        "  #!ffmpeg -y -loglevel info -i '/content/yoga_video/Abhay_Bhuj.mp4' -t 10 '/content/output/Abhay_Bhuj.mp4'\n",
        "  #!./build/examples/openpose/openpose.bin --keypoint_scale 3 --frame_step 3 --video '/content/output/Abhay_Bhuj.mp4' --write_json '/content/output/json/Abhay_Bhuj/' --display 0 --write_video '/content/output/openpose.avi'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6amI7HyBoeeV"
      },
      "source": [
        "# Download to local"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkBxnOVZMvvy"
      },
      "source": [
        "def download_file():\n",
        "  file_zip_name = \"\".join([output_file_path, '.zip'])\n",
        "  json_zip_name = \"\".join([output_json_path, '.zip'])\n",
        "\n",
        "  os.system(f\"zip -s 25 '{file_zip_name}' '{output_file_path}'\")\n",
        "  files.download(file_zip_name)\n",
        "  \n",
        "  os.system(f\"zip -s 25 '{json_zip_name}' '{output_json_path}'\")\n",
        "  files.download(json_zip_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc2pBAGuokmB"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUnDpxTZMy3y"
      },
      "source": [
        "for file_name in glob.glob(\"\".join([input_path, '/*', input_file_type])):   \n",
        "  detect_keypoint_file(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6pjX1hspcHB"
      },
      "source": [
        "# compute_OKS_rescale / compute_PDJ_rescale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZm-aLEwpZ2m"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import json\n",
        "from scipy.spatial import distance\n",
        "import math\n",
        "\n",
        "# json파일 폴더에서 180개의 json파일을 읽어 (x, y) tuple이 들어있는 4500 (25 keypoints * 180 frame) 벡터 추출\n",
        "def read_vec(json_path):\n",
        "    json_path = json_path\n",
        "    json_files = [f for f in listdir(json_path) if isfile(join(json_path, f))]\n",
        "    json_files.sort()\n",
        "\n",
        "    keypoint_data = []\n",
        "    for json_file in json_files:\n",
        "        #print(json_file)\n",
        "        with open(json_path+json_file) as f:\n",
        "            data = json.load(f)\n",
        "        ary = data[\"people\"][0][\"pose_keypoints_2d\"]\n",
        "        del ary[2::3]\n",
        "\n",
        "        # 코의 좌표 추출\n",
        "        nose_x = ary[0]\n",
        "        nose_y = ary[1]\n",
        "\n",
        "        odd = ary[0::2]\n",
        "        even = ary[1::2]\n",
        "\n",
        "        # 코의 좌표가 (0, 0)이 되게끔 모든 keypoint 위치를 이동 (shift)\n",
        "        origin_x = [x - nose_x for x in odd]\n",
        "        origin_y = [y - nose_y for y in even]\n",
        "\n",
        "        # 각 keypoint의 위치 정보를 (x, y)로 묶어서 list 안에 넣음\n",
        "        keypoint_data += tuple(zip(origin_x, origin_y))\n",
        "\n",
        "    return keypoint_data\n",
        "\n",
        "# PDJ (Percentage of Detected Joints) 계산식 중 diagonal에 해당하는 값을 base (length between nose and middle hip)의 형태로 구함\n",
        "def get_base(v1, v2):\n",
        "    # 스승과 학생의 base 길이를 각각 구함\n",
        "    base1 = distance.euclidean(v1[0], v1[8]) # 스승\n",
        "    base2 = distance.euclidean(v2[0], v2[8]) # 학생\n",
        "\n",
        "    scaling_factor = base1 / base2\n",
        "    \n",
        "    # 두 base의 평균을 기준 길이(PDJ의 diagonal)로 정함\n",
        "    result = (base1 + base2) / 2\n",
        "    return scaling_factor, result\n",
        "\n",
        "\n",
        "# OKS (Object Keypoint Similarity)를 계산\n",
        "# OKS = exp(-1.0 * (di ** 2) / (2 * alpha * base ** 2))\n",
        "def compute_oks(v1, v2, alpha):\n",
        "    scaling_factor, base = get_base(v1, v2)\n",
        "    nose_to_hip_len = alpha * base\n",
        "\n",
        "    oks = 0\n",
        "    for i in range(len(v1)):\n",
        "        # 학생(v2)의 좌표값에 대해 scaling_factor를 곱해 스승에 맞춤 \n",
        "        v2_scaled = tuple(scaling_factor * val for val in v2[i])\n",
        "\n",
        "        pointwise_dist = distance.euclidean(v1[i], v2_scaled)\n",
        "        oks += math.exp(-1.0 * pointwise_dist ** 2 / (2 * nose_to_hip_len ** 2))\n",
        "\n",
        "    result = oks / len(v1)\n",
        "    return result\n",
        "\n",
        "# PDJ (Percentage of Detected Joints)를 계산\n",
        "def compute_pdj(v1, v2, alpha):\n",
        "    scaling_factor, base = get_base(v1, v2)\n",
        "    nose_to_hip_len = alpha * base\n",
        "\n",
        "    pdj = 0\n",
        "    for i in range(len(v1)):\n",
        "        # 학생(v2)의 좌표값에 대해 scaling_factor를 곱해 스승에 맞춤 \n",
        "        v2_scaled = tuple(scaling_factor * val for val in v2[i])\n",
        "        #print(v2_scaled)\n",
        "        pointwise_dist = distance.euclidean(v1[i], v2_scaled)\n",
        "        if pointwise_dist < nose_to_hip_len:\n",
        "             pdj += 1\n",
        "\n",
        "    result = pdj * 1.0 / len(v1)\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnZst0mKpt7B"
      },
      "source": [
        "output_path_1 = '/content/output/json/Bhumi_Padam/'\n",
        "output_path_2 = '/content/output/json/Dristi_Padam/'\n",
        "\n",
        "output_path_3 = '/content/output/json/Santosh_vriksh/'\n",
        "output_path_4 = '/content/output/json/Sarthak_Vriksh/'\n",
        "\n",
        "case1 = read_vec(output_path_1)\n",
        "print(len(case1))\n",
        "#print(at)\n",
        "\n",
        "case2 = read_vec(output_path_2)\n",
        "print(len(case2))\n",
        "\n",
        "case3 = read_vec(output_path_3)\n",
        "print(len(case3))\n",
        "\n",
        "case4 = read_vec(output_path_4)\n",
        "print(len(case4))\n",
        "\n",
        "#alpha = 0.05\n",
        "#alpha = 0.08\n",
        "alpha = 0.1\n",
        "#alpha = 0.02\n",
        "\n",
        "\n",
        "print(\"simil_oks_1:\", compute_oks(case1, case2, alpha))\n",
        "print(\"simil_oks_2:\", compute_oks(case3, case4, alpha))\n",
        "print(\"simil_pdj_1:\", compute_pdj(case1, case2, alpha))\n",
        "print(\"simil_pdj_1:\", compute_pdj(case3, case4, alpha))\n",
        "\n",
        "print(\"dissimil_oks_1:\", compute_oks(case1, case3, alpha))\n",
        "print(\"dissimil_oks_2:\", compute_oks(case2, case4, alpha))\n",
        "print(\"dissimil_pdj_1:\", compute_pdj(case1, case3, alpha))\n",
        "print(\"dissimil_pdj_2:\", compute_pdj(case2, case4, alpha))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}