{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "openPose_googleDrive.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whRAmu12nNb5",
        "colab_type": "text"
      },
      "source": [
        "# google drive 연결"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB9tWW2puj8-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "41881ac1-f03c-48e9-cc15-c2db8c1822b3"
      },
      "source": [
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E79J2yPUzpyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf \"/content/openpose\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWYDYJJNnRky",
        "colab_type": "text"
      },
      "source": [
        "# cmake & git clone & Openpose build copy \n",
        " - google drive : My Drive/tmp/openpose  \n",
        " - 원본 : !cd openpose && rm -rf build || true && mkdir build && cd build && cmake .. && make -j`nproc` -> 결과 google drive로 cp\n",
        " - copy 후 openpose.bin 실행권한 부여"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySE28F2EztdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os.path import exists, join, basename, splitext\n",
        "\n",
        "git_repo_url = 'https://github.com/CMU-Perceptual-Computing-Lab/openpose.git'\n",
        "project_name = splitext(basename(git_repo_url))[0]\n",
        "if not exists(project_name):\n",
        "  # see: https://github.com/CMU-Perceptual-Computing-Lab/openpose/issues/949\n",
        "  # install new CMake becaue of CUDA10\n",
        "  !wget -q https://cmake.org/files/v3.13/cmake-3.13.0-Linux-x86_64.tar.gz"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2JY0y4szxi9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5ffe0adb-6520-492f-c250-581d08ca0c33"
      },
      "source": [
        "!tar xfz cmake-3.13.0-Linux-x86_64.tar.gz --strip-components=1 -C /usr/local\n",
        "# clone openpose\n",
        "!git clone -q --depth 1 $git_repo_url\n",
        "!sed -i 's/execute_process(COMMAND git checkout master WORKING_DIRECTORY ${CMAKE_SOURCE_DIR}\\/3rdparty\\/caffe)/execute_process(COMMAND git checkout f019d0dfe86f49d1140961f8c7dec22130c83154 WORKING_DIRECTORY ${CMAKE_SOURCE_DIR}\\/3rdparty\\/caffe)/g' openpose/CMakeLists.txt\n",
        "# install system dependencies\n",
        "!apt-get -qq install -y libatlas-base-dev libprotobuf-dev libleveldb-dev libsnappy-dev libhdf5-serial-dev protobuf-compiler libgflags-dev libgoogle-glog-dev liblmdb-dev opencl-headers ocl-icd-opencl-dev libviennacl-dev"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package libgflags2.2.\n",
            "(Reading database ... 144487 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libgflags2.2_2.2.1-1_amd64.deb ...\n",
            "Unpacking libgflags2.2 (2.2.1-1) ...\n",
            "Selecting previously unselected package libgflags-dev.\n",
            "Preparing to unpack .../01-libgflags-dev_2.2.1-1_amd64.deb ...\n",
            "Unpacking libgflags-dev (2.2.1-1) ...\n",
            "Selecting previously unselected package libgoogle-glog0v5.\n",
            "Preparing to unpack .../02-libgoogle-glog0v5_0.3.5-1_amd64.deb ...\n",
            "Unpacking libgoogle-glog0v5 (0.3.5-1) ...\n",
            "Selecting previously unselected package libgoogle-glog-dev.\n",
            "Preparing to unpack .../03-libgoogle-glog-dev_0.3.5-1_amd64.deb ...\n",
            "Unpacking libgoogle-glog-dev (0.3.5-1) ...\n",
            "Selecting previously unselected package libhdf5-serial-dev.\n",
            "Preparing to unpack .../04-libhdf5-serial-dev_1.10.0-patch1+docs-4_all.deb ...\n",
            "Unpacking libhdf5-serial-dev (1.10.0-patch1+docs-4) ...\n",
            "Selecting previously unselected package libleveldb1v5:amd64.\n",
            "Preparing to unpack .../05-libleveldb1v5_1.20-2_amd64.deb ...\n",
            "Unpacking libleveldb1v5:amd64 (1.20-2) ...\n",
            "Selecting previously unselected package libleveldb-dev:amd64.\n",
            "Preparing to unpack .../06-libleveldb-dev_1.20-2_amd64.deb ...\n",
            "Unpacking libleveldb-dev:amd64 (1.20-2) ...\n",
            "Selecting previously unselected package liblmdb0:amd64.\n",
            "Preparing to unpack .../07-liblmdb0_0.9.21-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking liblmdb0:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Selecting previously unselected package liblmdb-dev:amd64.\n",
            "Preparing to unpack .../08-liblmdb-dev_0.9.21-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking liblmdb-dev:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libprotobuf-lite10:amd64.\n",
            "Preparing to unpack .../09-libprotobuf-lite10_3.0.0-9.1ubuntu1_amd64.deb ...\n",
            "Unpacking libprotobuf-lite10:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Selecting previously unselected package lmdb-doc.\n",
            "Preparing to unpack .../10-lmdb-doc_0.9.21-1ubuntu0.1_all.deb ...\n",
            "Unpacking lmdb-doc (0.9.21-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libprotobuf-dev:amd64.\n",
            "Preparing to unpack .../11-libprotobuf-dev_3.0.0-9.1ubuntu1_amd64.deb ...\n",
            "Unpacking libprotobuf-dev:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Selecting previously unselected package libsnappy-dev:amd64.\n",
            "Preparing to unpack .../12-libsnappy-dev_1.1.7-1_amd64.deb ...\n",
            "Unpacking libsnappy-dev:amd64 (1.1.7-1) ...\n",
            "Selecting previously unselected package libviennacl-dev.\n",
            "Preparing to unpack .../13-libviennacl-dev_1.7.1+dfsg1-2ubuntu1_all.deb ...\n",
            "Unpacking libviennacl-dev (1.7.1+dfsg1-2ubuntu1) ...\n",
            "Selecting previously unselected package opencl-clhpp-headers.\n",
            "Preparing to unpack .../14-opencl-clhpp-headers_2.0.10+git12-g5dd8bb9-1_all.deb ...\n",
            "Unpacking opencl-clhpp-headers (2.0.10+git12-g5dd8bb9-1) ...\n",
            "Selecting previously unselected package opencl-headers.\n",
            "Preparing to unpack .../15-opencl-headers_2.2~2018.02.21-gb5c3680-1_all.deb ...\n",
            "Unpacking opencl-headers (2.2~2018.02.21-gb5c3680-1) ...\n",
            "Setting up libviennacl-dev (1.7.1+dfsg1-2ubuntu1) ...\n",
            "Setting up libgflags2.2 (2.2.1-1) ...\n",
            "Setting up libgflags-dev (2.2.1-1) ...\n",
            "Setting up liblmdb0:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Setting up opencl-clhpp-headers (2.0.10+git12-g5dd8bb9-1) ...\n",
            "Setting up libleveldb1v5:amd64 (1.20-2) ...\n",
            "Setting up libhdf5-serial-dev (1.10.0-patch1+docs-4) ...\n",
            "Setting up libsnappy-dev:amd64 (1.1.7-1) ...\n",
            "Setting up libgoogle-glog0v5 (0.3.5-1) ...\n",
            "Setting up liblmdb-dev:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Setting up lmdb-doc (0.9.21-1ubuntu0.1) ...\n",
            "Setting up libprotobuf-lite10:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Setting up opencl-headers (2.2~2018.02.21-gb5c3680-1) ...\n",
            "Setting up libprotobuf-dev:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Setting up libleveldb-dev:amd64 (1.20-2) ...\n",
            "Setting up libgoogle-glog-dev (0.3.5-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMimD2dLu1Ab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r \"/content/drive/My Drive/tmp/openpose/\" /content/"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXH6rMYqvA8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -ltr /content/openpose/build/examples/openpose\n",
        "!chmod u+x /content/openpose/build/examples/openpose/openpose.bin\n",
        "!ls -ltr /content/openpose/build/examples/openpose"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDNWdgNNoCZt",
        "colab_type": "text"
      },
      "source": [
        "# Input data copy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6Pu5WLnvX2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf \"./yoga_video/\"\n",
        "os.mkdir(\"./yoga_video/\")\n",
        "\n",
        "!wget -q https://archive.org/download/YogaVidCollected/Yoga_Vid_Collected.zip "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiV2xZuDvava",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip Yoga_Vid_Collected.zip -d yoga_video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6uqNj9uoIvv",
        "colab_type": "text"
      },
      "source": [
        "# Openpose model/input/output path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "webRPSzvKSe2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "model_path = '/content/openpose'  \n",
        "input_path = '/content/yoga_video'\n",
        "output_path = '/content/output'\n",
        "output_file_path = \"\".join([output_path, '/file'])\n",
        "output_json_path = \"\".join([output_path, '/json'])\n",
        "\n",
        "os.system(f\"rm -rf '{output_path}'\")\n",
        "os.mkdir(output_path)\n",
        "os.mkdir(output_file_path)\n",
        "os.mkdir(output_json_path)\n",
        "\n",
        "input_file_type = \"mp4\"\n",
        "input_cut_time = 10\n",
        "\n",
        "%cd $model_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tguLACxyoWtN",
        "colab_type": "text"
      },
      "source": [
        "# Pose Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ET9rU81Mr6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def detect_keypoint_file(file_name):\n",
        "\n",
        "  origin_file_path = \"\".join([output_path, '/', file_name.split('/')[-1]])\n",
        "  origin_file_name = file_name.split('/')[-1].split('.')[0]\n",
        "\n",
        "  temp_file_name = \"\".join([output_path, '/', 'openpose.avi'])\n",
        "  output_file_name = \"\".join([output_file_path, '/', origin_file_name, '.', input_file_type])\n",
        "  output_json_name = \"\".join([output_json_path, '/', origin_file_name])\n",
        "    \n",
        "  os.system(f\"ffmpeg -y -loglevel info -i '{file_name}' -t {input_cut_time} '{origin_file_path}'\")\n",
        "  os.system(f\"./build/examples/openpose/openpose.bin --keypoint_scale 3 --frame_step 3 --video '{origin_file_path}' --write_json '{output_json_name}/' --display 0 --write_video '{temp_file_name}'\")\n",
        "  os.system(f\"ffmpeg -y -loglevel info -i '{temp_file_name}' '{output_file_name}'\")\n",
        "  os.system(f\"rm -rf '{origin_file_path}'\")\n",
        "  os.system(f\"rm -rf '{temp_file_name}'\")\n",
        "  #!ffmpeg -y -loglevel info -i '/content/yoga_video/Abhay_Bhuj.mp4' -t 10 '/content/output/Abhay_Bhuj.mp4'\n",
        "  #!./build/examples/openpose/openpose.bin --keypoint_scale 3 --frame_step 3 --video '/content/output/Abhay_Bhuj.mp4' --write_json '/content/output/json/Abhay_Bhuj/' --display 0 --write_video '/content/output/openpose.avi'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6amI7HyBoeeV",
        "colab_type": "text"
      },
      "source": [
        "# Download to local"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkBxnOVZMvvy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_file():\n",
        "  file_zip_name = \"\".join([output_file_path, '.zip'])\n",
        "  json_zip_name = \"\".join([output_json_path, '.zip'])\n",
        "\n",
        "  os.system(f\"zip -s 25 '{file_zip_name}' '{output_file_path}'\")\n",
        "  files.download(file_zip_name)\n",
        "  \n",
        "  os.system(f\"zip -s 25 '{json_zip_name}' '{output_json_path}'\")\n",
        "  files.download(json_zip_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc2pBAGuokmB",
        "colab_type": "text"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUnDpxTZMy3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for file_name in glob.glob(\"\".join([input_path, '/*', input_file_type])):   \n",
        "  detect_keypoint_file(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6pjX1hspcHB",
        "colab_type": "text"
      },
      "source": [
        "# compute_OKS_rescale / compute_PDJ_rescale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZm-aLEwpZ2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import json\n",
        "from scipy.spatial import distance\n",
        "import math\n",
        "\n",
        "# json파일 폴더에서 180개의 json파일을 읽어 (x, y) tuple이 들어있는 4500 (25 keypoints * 180 frame) 벡터 추출\n",
        "def read_vec(json_path):\n",
        "    json_path = json_path\n",
        "    json_files = [f for f in listdir(json_path) if isfile(join(json_path, f))]\n",
        "    json_files.sort()\n",
        "\n",
        "    keypoint_data = []\n",
        "    for json_file in json_files:\n",
        "        #print(json_file)\n",
        "        with open(json_path+json_file) as f:\n",
        "            data = json.load(f)\n",
        "        ary = data[\"people\"][0][\"pose_keypoints_2d\"]\n",
        "        del ary[2::3]\n",
        "\n",
        "        # 코의 좌표 추출\n",
        "        nose_x = ary[0]\n",
        "        nose_y = ary[1]\n",
        "\n",
        "        odd = ary[0::2]\n",
        "        even = ary[1::2]\n",
        "\n",
        "        # 코의 좌표가 (0, 0)이 되게끔 모든 keypoint 위치를 이동 (shift)\n",
        "        origin_x = [x - nose_x for x in odd]\n",
        "        origin_y = [y - nose_y for y in even]\n",
        "\n",
        "        # 각 keypoint의 위치 정보를 (x, y)로 묶어서 list 안에 넣음\n",
        "        keypoint_data += tuple(zip(origin_x, origin_y))\n",
        "\n",
        "    return keypoint_data\n",
        "\n",
        "# PDJ (Percentage of Detected Joints) 계산식 중 diagonal에 해당하는 값을 base (length between nose and middle hip)의 형태로 구함\n",
        "def get_base(v1, v2):\n",
        "    # 스승과 학생의 base 길이를 각각 구함\n",
        "    base1 = distance.euclidean(v1[0], v1[8]) # 스승\n",
        "    base2 = distance.euclidean(v2[0], v2[8]) # 학생\n",
        "\n",
        "    scaling_factor = base1 / base2\n",
        "    \n",
        "    # 두 base의 평균을 기준 길이(PDJ의 diagonal)로 정함\n",
        "    result = (base1 + base2) / 2\n",
        "    return scaling_factor, result\n",
        "\n",
        "\n",
        "# OKS (Object Keypoint Similarity)를 계산\n",
        "# OKS = exp(-1.0 * (di ** 2) / (2 * alpha * base ** 2))\n",
        "def compute_oks(v1, v2, alpha):\n",
        "    scaling_factor, base = get_base(v1, v2)\n",
        "    nose_to_hip_len = alpha * base\n",
        "\n",
        "    oks = 0\n",
        "    for i in range(len(v1)):\n",
        "        # 학생(v2)의 좌표값에 대해 scaling_factor를 곱해 스승에 맞춤 \n",
        "        v2_scaled = tuple(scaling_factor * val for val in v2[i])\n",
        "\n",
        "        pointwise_dist = distance.euclidean(v1[i], v2_scaled)\n",
        "        oks += math.exp(-1.0 * pointwise_dist ** 2 / (2 * nose_to_hip_len ** 2))\n",
        "\n",
        "    result = oks / len(v1)\n",
        "    return result\n",
        "\n",
        "# PDJ (Percentage of Detected Joints)를 계산\n",
        "def compute_pdj(v1, v2, alpha):\n",
        "    scaling_factor, base = get_base(v1, v2)\n",
        "    nose_to_hip_len = alpha * base\n",
        "\n",
        "    pdj = 0\n",
        "    for i in range(len(v1)):\n",
        "        # 학생(v2)의 좌표값에 대해 scaling_factor를 곱해 스승에 맞춤 \n",
        "        v2_scaled = tuple(scaling_factor * val for val in v2[i])\n",
        "        #print(v2_scaled)\n",
        "        pointwise_dist = distance.euclidean(v1[i], v2_scaled)\n",
        "        if pointwise_dist < nose_to_hip_len:\n",
        "             pdj += 1\n",
        "\n",
        "    result = pdj * 1.0 / len(v1)\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnZst0mKpt7B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "f0b818e4-1d00-420d-e3ce-d53ce0a7b1bb"
      },
      "source": [
        "output_path_1 = '/content/output/json/Bhumi_Padam/'\n",
        "output_path_2 = '/content/output/json/Dristi_Padam/'\n",
        "\n",
        "output_path_3 = '/content/output/json/Santosh_vriksh/'\n",
        "output_path_4 = '/content/output/json/Sarthak_Vriksh/'\n",
        "\n",
        "case1 = read_vec(output_path_1)\n",
        "print(len(case1))\n",
        "#print(at)\n",
        "\n",
        "case2 = read_vec(output_path_2)\n",
        "print(len(case2))\n",
        "\n",
        "case3 = read_vec(output_path_3)\n",
        "print(len(case3))\n",
        "\n",
        "case4 = read_vec(output_path_4)\n",
        "print(len(case4))\n",
        "\n",
        "#alpha = 0.05\n",
        "#alpha = 0.08\n",
        "alpha = 0.1\n",
        "#alpha = 0.02\n",
        "\n",
        "\n",
        "print(\"simil_oks_1:\", compute_oks(case1, case2, alpha))\n",
        "print(\"simil_oks_2:\", compute_oks(case3, case4, alpha))\n",
        "print(\"simil_pdj_1:\", compute_pdj(case1, case2, alpha))\n",
        "print(\"simil_pdj_1:\", compute_pdj(case3, case4, alpha))\n",
        "\n",
        "print(\"dissimil_oks_1:\", compute_oks(case1, case3, alpha))\n",
        "print(\"dissimil_oks_2:\", compute_oks(case2, case4, alpha))\n",
        "print(\"dissimil_pdj_1:\", compute_pdj(case1, case3, alpha))\n",
        "print(\"dissimil_pdj_2:\", compute_pdj(case2, case4, alpha))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2500\n",
            "2500\n",
            "2500\n",
            "2500\n",
            "simil_oks_1: 0.40759016548302096\n",
            "simil_oks_2: 0.48734690328838176\n",
            "simil_pdj_1: 0.3652\n",
            "simil_pdj_1: 0.454\n",
            "dissimil_oks_1: 0.4234780170517333\n",
            "dissimil_oks_2: 0.31184113467882746\n",
            "dissimil_pdj_1: 0.4216\n",
            "dissimil_pdj_2: 0.2524\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}